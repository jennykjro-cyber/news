import streamlit as st
import pandas as pd
from gnews import GNews
from datetime import datetime, timedelta
from io import BytesIO
import json
import os

# =================================================
# 1. ì‹œìŠ¤í…œ ì´ˆê¸° ì„¤ì • ë° ë°ì´í„° ë¡œë“œ
# =================================================
DB_FILE = "keywords_db.json"

def load_keywords():
    if os.path.exists(DB_FILE):
        try:
            with open(DB_FILE, "r", encoding="utf-8") as f:
                return json.load(f)
        except:
            pass
    return {
        "ìœ í†µ": ["í™ˆí”ŒëŸ¬ìŠ¤", "ì´ë§ˆíŠ¸", "ë¡¯ë°ë§ˆíŠ¸"],
        "í¸ì˜ì ": ["GS25", "CU"],
        "ìœ¡ê°€ê³µ": ["ìœ¡ê°€ê³µ", "í–„", "ì†Œì‹œì§€", "ë¹„ì—”ë‚˜"],
        "HMR": ["HMR", "ë°€í‚¤íŠ¸"],
        "ëŒ€ì²´ìœ¡": ["ëŒ€ì²´ìœ¡", "ì‹ë¬¼ì„±"],
        "ì‹œì¥ë™í–¥": ["ê°€ê²©ì¸ìƒ", "ì›ê°€", "ë¬¼ê°€", "ì‹í’ˆ ë§¤ì¶œ"]
    }

def save_keywords(mapping):
    with open(DB_FILE, "w", encoding="utf-8") as f:
        json.dump(mapping, f, ensure_ascii=False, indent=4)

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” (ì˜¤ë¥˜ ë°©ì§€ í•µì‹¬)
if "keyword_mapping" not in st.session_state:
    st.session_state.keyword_mapping = load_keywords()
if "news_results" not in st.session_state:
    st.session_state.news_results = []
if "cart_list" not in st.session_state: # DataFrame ëŒ€ì‹  ë¦¬ìŠ¤íŠ¸ë¡œ ê´€ë¦¬í•˜ì—¬ TypeError ë°©ì§€
    st.session_state.cart_list = []
if "reset_key" not in st.session_state:
    st.session_state.reset_key = 0

# =================================================
# 2. í•µì‹¬ ë¡œì§ í•¨ìˆ˜
# =================================================
def get_fixed_date_range():
    today = datetime.today()
    this_thursday = today - timedelta(days=(today.weekday() - 3) % 7)
    last_friday = this_thursday - timedelta(days=6)
    return last_friday.date(), this_thursday.date()

def parse_news_date(date_str):
    try:
        return datetime.strptime(date_str, "%a, %d %b %Y %H:%M:%S %Z").date()
    except:
        return None

def get_relevance_score(title, desc, all_keywords):
    score = 0
    text = f"{title} {desc}".replace(" ", "").lower()
    title_only = title.replace(" ", "").lower()
    for kw in all_keywords:
        target = kw.replace(" ", "").lower()
        if target in title_only: score += 2
        elif target in text: score += 1
    return score

def collect_news_final(mapping, start_date, end_date):
    google_news = GNews(language="ko", country="KR", max_results=15)
    all_rows = []
    all_search_kws = [kw for sublist in mapping.values() for kw in sublist]
    exclude_keywords = ["ì¶œì‹œ", "ëŸ°ì¹­", "ì‹ ì œí’ˆ", "ì´ë²¤íŠ¸", "ì¦ì •", "í• ì¸í–‰ì‚¬", "í¬í† ì¡´", "íŒì—…ìŠ¤í† ì–´"]
    
    progress_bar = st.progress(0)
    groups = list(mapping.items())
    
    for i, (group, sub_kws) in enumerate(groups):
        for kw in sub_kws:
            articles = google_news.get_news(kw)
            for a in articles:
                title = a.get("title", "ì œëª© ì—†ìŒ")
                if any(ex in title for ex in exclude_keywords): continue
                
                article_date = parse_news_date(a.get("published date", ""))
                if not article_date or not (start_date <= article_date <= end_date): continue
                
                desc = a.get("description", "")
                score = get_relevance_score(title, desc, all_search_kws)
                all_rows.append({
                    "ê·¸ë£¹": group,
                    "ì¶œì²˜": a.get("publisher", {}).get("title", "ì¶œì²˜ ë¯¸ìƒ"),
                    "ê¸°ì‚¬ì¼ì": article_date.strftime("%Y-%m-%d"),
                    "ì œëª©": title,
                    "ë§í¬": a.get("url", ""),
                    "ì—°ê´€ë„ì ìˆ˜": score
                })
        progress_bar.progress((i + 1) / len(groups))
    
    # ì¤‘ë³µ ì œê±°
    unique_rows = {r['ë§í¬']: r for r in all_rows}.values()
    return list(unique_rows)

def to_excel(data_list):
    df = pd.DataFrame(data_list)
    output = BytesIO()
    with pd.ExcelWriter(output, engine="xlsxwriter") as writer:
        df[["ê·¸ë£¹", "ì¶œì²˜", "ê¸°ì‚¬ì¼ì", "ì œëª©"]].to_excel(writer, index=False, sheet_name="ë‰´ìŠ¤í´ë¦¬í•‘")
        workbook = writer.book
        worksheet = writer.sheets["ë‰´ìŠ¤í´ë¦¬í•‘"]
        link_format = workbook.add_format({'font_color': 'blue', 'underline': 1})
        for row_num, link in enumerate(df['ë§í¬']):
            worksheet.write_url(row_num + 1, 3, link, link_format, df.iloc[row_num]['ì œëª©'])
        worksheet.set_column('A:C', 15)
        worksheet.set_column('D:D', 80)
    return output.getvalue()

# =================================================
# 3. í™”ë©´ UI êµ¬ì„± (ë ˆì´ì•„ì›ƒ ìµœì í™”)
# =================================================
st.set_page_config(page_title="ì§„ì£¼í–„ ë‰´ìŠ¤ í´ë¦¬í•‘", layout="wide")

# íƒ€ì´í‹€ ë° ê¸°ê°„ ì„¤ì • ì˜ì—­ (ì™¼ìª½ ì •ë ¬ ì¤‘ì‹¬)
st.title("ğŸ—ï¸ ì£¼ê°„ ë‰´ìŠ¤ í´ë¦¬í•‘ ì‹œìŠ¤í…œ")
start_d, end_d = get_fixed_date_range()
st.markdown(f"ğŸ—“ï¸ **ìˆ˜ì§‘ ëŒ€ìƒ ê¸°ê°„:** `{start_d}` ~ `{end_d}`")

# ì„¤ì • ë° ì‹¤í–‰ ì˜ì—­
st.divider()
col_setup1, col_setup2 = st.columns([1.5, 3])

with col_setup1:
    st.subheader("ğŸ” ìˆ˜ì§‘ ë° í•„í„°")
    min_score = st.number_input("ì—…ë¬´ ì—°ê´€ë„ ìµœì†Œ ì ìˆ˜ (0~10)", min_value=0, max_value=10, value=3)
    if st.button("ğŸŒŸ ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹œì‘", type="primary", use_container_width=True):
        with st.spinner('ë‰´ìŠ¤ë¥¼ ìˆ˜ì§‘í•˜ê³  ìˆìŠµë‹ˆë‹¤...'):
            st.session_state.news_results = collect_news_final(st.session_state.keyword_mapping, start_d, end_d)
            st.session_state.cart_list = []
            st.rerun()

with col_setup2:
    # í‚¤ì›Œë“œ ê´€ë¦¬ (í•­ìƒ ì ‘í˜€ìˆìŒ)
    with st.expander("ğŸ› ï¸ ë‰´ìŠ¤í´ë¦¬í•‘ í‚¤ì›Œë“œ ê´€ë¦¬ (í´ë¦­í•˜ì—¬ ì—´ê¸°)", expanded=False):
        mg_c1, mg_c2 = st.columns(2)
        with mg_c1:
            new_g = st.text_input("ìƒˆ ëŒ€ë¶„ë¥˜ ì¶”ê°€")
            if st.button("ëŒ€ë¶„ë¥˜ ì¶”ê°€"):
                if new_g and new_g not in st.session_state.keyword_mapping:
                    st.session_state.keyword_mapping[new_g] = []
                    save_keywords(st.session_state.keyword_mapping)
                    st.rerun()
        with mg_c2:
            keys = list(st.session_state.keyword_mapping.keys())
            if keys:
                sel_g = st.selectbox("ëŒ€ë¶„ë¥˜ ì„ íƒ", options=keys)
                new_s = st.text_input(f"'{sel_g}'ì— ì†Œë¶„ë¥˜ í‚¤ì›Œë“œ ì¶”ê°€")
                if st.button("ì†Œë¶„ë¥˜ ì¶”ê°€"):
                    if new_s and new_s not in st.session_state.keyword_mapping[sel_g]:
                        st.session_state.keyword_mapping[sel_g].append(new_s)
                        save_keywords(st.session_state.keyword_mapping)
                        st.rerun()
        st.write("---")
        for g, subs in list(st.session_state.keyword_mapping.items()):
            cg, cs = st.columns([1, 4])
            if cg.button(f"ğŸ—‘ï¸ {g}", key=f"del_{g}"):
                del st.session_state.keyword_mapping[g]
                save_keywords(st.session_state.keyword_mapping)
                st.rerun()
            cs.write(f"**{g}**: {', '.join(subs)}")

st.divider()

# ê²°ê³¼ ì¶œë ¥ ì˜ì—­
col_list, col_cart = st.columns([1.2, 0.8])

with col_list:
    st.subheader("ğŸ“Œ ìˆ˜ì§‘ëœ ë‰´ìŠ¤ ë¦¬ìŠ¤íŠ¸")
    filtered_res = [r for r in st.session_state.news_results if r.get('ì—°ê´€ë„ì ìˆ˜', 0) >= min_score]
    
    if filtered_res:
        st.caption(f"ì´ {len(filtered_res)}ê±´ì˜ ê¸°ì‚¬ê°€ ê²€ìƒ‰ë˜ì—ˆìŠµë‹ˆë‹¤.")
        for idx, item in enumerate(filtered_res):
            cb_key = f"news_{idx}_v{st.session_state.reset_key}"
            # ì²´í¬ë°•ìŠ¤ ì„ íƒ ì‹œ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€
            if st.checkbox(f"[{item.get('ê·¸ë£¹')}] {item['ì œëª©']} (ì ìˆ˜:{item['ì—°ê´€ë„ì ìˆ˜']})", key=cb_key):
                if item not in st.session_state.cart_list:
                    st.session_state.cart_list.append(item)
    elif st.session_state.news_results:
        st.warning(f"ì ìˆ˜ {min_score}ì  ì´ìƒì¸ ê¸°ì‚¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        st.info("ì™¼ìª½ 'ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹œì‘' ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.")

with col_cart:
    st.subheader("ğŸ›’ ì¶”ì¶œ ë°”êµ¬ë‹ˆ")
    if st.session_state.cart_list:
        cart_df = pd.DataFrame(st.session_state.cart_list)
        st.dataframe(cart_df[["ê·¸ë£¹", "ì¶œì²˜", "ì œëª©"]], use_container_width=True, hide_index=True)
        
        file_name = f"ì§„ì£¼í–„ ë‰´ìŠ¤í´ë¦¬í•‘ ({end_d.strftime('%Y%m%d')}).xlsx"
        st.download_button(
            label="ğŸ“¥ ì—‘ì…€ ë‹¤ìš´ë¡œë“œ",
            data=to_excel(st.session_state.cart_list),
            file_name=file_name,
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            use_container_width=True
        )
        
        if st.button("ğŸ”„ ì„ íƒ ì „ì²´ í•´ì œ", use_container_width=True):
            st.session_state.reset_key += 1
            st.session_state.cart_list = []
            st.rerun()
    else:
        st.write("ì„ íƒëœ ê¸°ì‚¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
