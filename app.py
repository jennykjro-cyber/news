import streamlit as st
import pandas as pd
from gnews import GNews
from datetime import datetime, timedelta
from io import BytesIO

# =================================================
# ì„¤ì •
# =================================================
BUSINESS_KEYWORDS = [
    "ìœ¡ê°€ê³µ", "í–„", "ì†Œì‹œì§€", "ì‹í’ˆ",
    "ì›ê°€", "ê°€ê²©", "ê°€ê²©ì¸ìƒ",
    "ë§ˆì¼€íŒ…", "ë¸Œëœë“œ", "ìœ í†µ",
    "í¸ì˜ì ", "ëŒ€ì²´ìœ¡", "ì‹œì¥", "ë§¤ì¶œ"
]

google_news = GNews(
    language="ko",
    country="KR",
    max_results=50
)

# =================================================
# ë‚ ì§œ ê´€ë ¨ í•¨ìˆ˜
# =================================================
def get_date_range():
    """
    ì „ì£¼ í† ìš”ì¼ ~ ì´ë²ˆì£¼ ëª©ìš”ì¼
    """
    today = datetime.today()

    # ì´ë²ˆì£¼ ëª©ìš”ì¼ (weekday: ì›”0 ~ ì¼6, ëª©ìš”ì¼=3)
    this_thursday = today - timedelta(days=(today.weekday() - 3) % 7)

    # ì „ì£¼ í† ìš”ì¼
    last_saturday = this_thursday - timedelta(days=5)

    return last_saturday.date(), this_thursday.date()


def parse_news_date(date_str):
    """
    Google News ê¸°ì‚¬ ë‚ ì§œ ë¬¸ìì—´ â†’ date
    """
    try:
        return datetime.strptime(
            date_str, "%a, %d %b %Y %H:%M:%S %Z"
        ).date()
    except:
        return None

# =================================================
# ì—°ê´€ë„ ê³„ì‚°
# =================================================
def relevance_score(text: str) -> int:
    score = 0
    for kw in BUSINESS_KEYWORDS:
        if kw in text:
            score += 1
    return score

# =================================================
# ë‰´ìŠ¤ ìˆ˜ì§‘
# =================================================
def collect_news(keyword: str, start_date, end_date):
    articles = google_news.get_news(keyword)
    rows = []

    for a in articles:
        raw_date = a.get("published date", "")
        article_date = parse_news_date(raw_date)

        # ë‚ ì§œ íŒŒì‹± ì‹¤íŒ¨ ì‹œ ì œì™¸
        if article_date is None:
            continue

        # ê¸°ê°„ í•„í„°
        if not (start_date <= article_date <= end_date):
            continue

        title = a.get("title", "")
        description = a.get("description", "")
        content = f"{title} {description}"

        score = relevance_score(content)

        rows.append({
            "ê²€ìƒ‰í‚¤ì›Œë“œ": keyword,
            "ì¶œì²˜": a.get("publisher", {}).get("title", ""),
            "ê¸°ì‚¬ì¼ì": article_date.strftime("%Y-%m-%d"),
            "ì œëª©": title,
            "ë§í¬": a.get("url", ""),
            "ì—°ê´€ë„ì ìˆ˜": score
        })

    return pd.DataFrame(rows)

# =================================================
# ì—‘ì…€ ë³€í™˜
# =================================================
def to_excel(df: pd.DataFrame):
    output = BytesIO()
    with pd.ExcelWriter(output, engine="openpyxl") as writer:
        df.to_excel(writer, index=False)
    return output.getvalue()

# =================================================
# Streamlit UI
# =================================================
st.title("ğŸ“° ì‹í’ˆ/ìœ¡ê°€ê³µ ë‰´ìŠ¤ ìŠ¤í¬ë© ìë™í™”")

start_date, end_date = get_date_range()
st.caption(f"ğŸ“… ê¸°ì‚¬ ìˆ˜ì§‘ ê¸°ê°„: {start_date} ~ {end_date}")

keyword = st.text_input("ğŸ” ê²€ìƒ‰ í‚¤ì›Œë“œ ì…ë ¥")

min_score = st.slider(
    "ì—…ë¬´ ì—°ê´€ë„ í•„í„° (ì ìˆ˜ ì´ìƒë§Œ í‘œì‹œ)",
    min_value=0,
    max_value=5,
    value=2
)

if "cart" not in st.session_state:
    st.session_state.cart = pd.DataFrame()

if st.button("ê¸°ì‚¬ ìˆ˜ì§‘"):
    if not keyword:
        st.warning("í‚¤ì›Œë“œë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
    else:
        df = collect_news(keyword, start_date, end_date)
        df = df[df["ì—°ê´€ë„ì ìˆ˜"] >= min_score]

        if df.empty:
            st.info("ì¡°ê±´ì— ë§ëŠ” ê¸°ì‚¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
        else:
            st.subheader("ğŸ“Œ ìˆ˜ì§‘ëœ ê¸°ì‚¬")

            for idx, row in df.iterrows():
                checked = st.checkbox(
                    f"[{row['ì¶œì²˜']}] {row['ì œëª©']} ({row['ê¸°ì‚¬ì¼ì']})",
                    key=f"chk_{idx}"
                )

                if checked:
                    st.session_state.cart = pd.concat(
                        [st.session_state.cart, pd.DataFrame([row])],
                        ignore_index=True
                    )

# =================================================
# ì¥ë°”êµ¬ë‹ˆ ì˜ì—­
# =================================================
st.subheader("ğŸ›’ ì„ íƒí•œ ê¸°ì‚¬")

if not st.session_state.cart.empty:
    display_df = st.session_state.cart.drop_duplicates(
        subset=["ì œëª©", "ë§í¬"]
    ).copy()

    display_df["ì œëª©(í•˜ì´í¼ë§í¬)"] = display_df.apply(
        lambda x: f'=HYPERLINK("{x["ë§í¬"]}", "{x["ì œëª©"]}")',
        axis=1
    )

    final_df = display_df[
        ["ê²€ìƒ‰í‚¤ì›Œë“œ", "ì¶œì²˜", "ê¸°ì‚¬ì¼ì", "ì œëª©(í•˜ì´í¼ë§í¬)"]
    ]

    st.dataframe(final_df, use_container_width=True)

    excel_data = to_excel(final_df)

    st.download_button(
        label="ğŸ“¥ ì—‘ì…€ ë‹¤ìš´ë¡œë“œ",
        data=excel_data,
        file_name="news_scrap.xlsx",
        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
    )
else:
    st.info("ì„ íƒí•œ ê¸°ì‚¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
