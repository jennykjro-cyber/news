import streamlit as st
import pandas as pd
from gnews import GNews
from datetime import datetime, timedelta
from io import BytesIO
import json
import os

# =================================================
# 1. ì‹œìŠ¤í…œ ì´ˆê¸° ì„¤ì • ë° ë°ì´í„° ë¡œë“œ
# =================================================
DB_FILE = "keywords_db.json"

def load_keywords():
    if os.path.exists(DB_FILE):
        try:
            with open(DB_FILE, "r", encoding="utf-8") as f:
                return json.load(f)
        except:
            pass
    return {
        "ìœ í†µ": ["í™ˆí”ŒëŸ¬ìŠ¤", "ì´ë§ˆíŠ¸", "ë¡¯ë°ë§ˆíŠ¸"],
        "í¸ì˜ì ": ["GS25", "CU"],
        "ìœ¡ê°€ê³µ": ["ìœ¡ê°€ê³µ", "í–„", "ì†Œì‹œì§€", "ë¹„ì—”ë‚˜"],
        "HMR": ["HMR", "ë°€í‚¤íŠ¸"],
        "ëŒ€ì²´ìœ¡": ["ëŒ€ì²´ìœ¡", "ì‹ë¬¼ì„±"],
        "ì‹œì¥ë™í–¥": ["ê°€ê²©ì¸ìƒ", "ì›ê°€", "ë¬¼ê°€", "ì‹í’ˆ ë§¤ì¶œ"]
    }

def save_keywords(mapping):
    with open(DB_FILE, "w", encoding="utf-8") as f:
        json.dump(mapping, f, ensure_ascii=False, indent=4)

if "keyword_mapping" not in st.session_state:
    st.session_state.keyword_mapping = load_keywords()
if "news_results" not in st.session_state:
    st.session_state.news_results = []
if "cart_list" not in st.session_state:
    st.session_state.cart_list = []

# =================================================
# 2. í•µì‹¬ ë¡œì§
# =================================================
def get_fixed_date_range():
    today = datetime.today()
    days_since_friday = (today.weekday() - 4) % 7
    last_friday = today - timedelta(days=days_since_friday)
    return last_friday.date(), today.date()

def parse_news_date(date_str):
    try:
        return datetime.strptime(date_str, "%a, %d %b %Y %H:%M:%S %Z").date()
    except:
        return None

def get_relevance_score(title, desc, all_keywords):
    score = 0
    text = f"{title} {desc}".replace(" ", "").lower()
    title_only = title.replace(" ", "").lower()
    for kw in all_keywords:
        t = kw.replace(" ", "").lower()
        if t in title_only: score += 2
        elif t in text: score += 1
    return score

def collect_news_final(mapping, start_date, end_date):
    google_news = GNews(language="ko", country="KR", max_results=25)
    rows = []
    all_kws = [kw for subs in mapping.values() for kw in subs]
    exclude = ["ì¶œì‹œ", "ëŸ°ì¹­", "ì‹ ì œí’ˆ", "ì´ë²¤íŠ¸", "ì¦ì •", "í• ì¸í–‰ì‚¬", "ì¦ì‹œ", "ì£¼ê°€"]

    for g, subs in mapping.items():
        if not subs:
            continue
        q = f"{g} ({' OR '.join(subs)})"
        for a in google_news.get_news(q):
            title = a.get("title", "")
            if any(e in title for e in exclude):
                continue
            d = parse_news_date(a.get("published date", ""))
            if not d or not (start_date <= d <= end_date):
                continue
            rows.append({
                "í‚¤ì›Œë“œ": g,
                "ì¶œì²˜": a.get("publisher", {}).get("title", ""),
                "ê¸°ì‚¬ì¼ì": d.strftime("%Y-%m-%d"),
                "ì œëª©": title,
                "ë§í¬": a.get("url", ""),
                "ì—°ê´€ë„ì ìˆ˜": get_relevance_score(title, a.get("description", ""), all_kws)
            })
    uniq = {r["ë§í¬"]: r for r in rows}.values()
    return sorted(uniq, key=lambda x: x["ì—°ê´€ë„ì ìˆ˜"], reverse=True)

def to_excel(data):
    df = pd.DataFrame(data)
    output = BytesIO()
    with pd.ExcelWriter(output, engine="xlsxwriter") as writer:
        df[["í‚¤ì›Œë“œ", "ì¶œì²˜", "ê¸°ì‚¬ì¼ì", "ì œëª©"]].to_excel(writer, index=False)
    return output.getvalue()

# =================================================
# 3. UI
# =================================================
st.set_page_config(page_title="ì§„ì£¼í–„ ë‰´ìŠ¤ í´ë¦¬í•‘", layout="wide")

def toggle_cart_item(item, key):
    checked = st.session_state[key]
    links = [c["ë§í¬"] for c in st.session_state.cart_list]
    if checked and item["ë§í¬"] not in links:
        st.session_state.cart_list.append(item)
    if not checked:
        st.session_state.cart_list = [c for c in st.session_state.cart_list if c["ë§í¬"] != item["ë§í¬"]]

def add_group():
    g = st.session_state.new_group_input.strip()
    if g and g not in st.session_state.keyword_mapping:
        st.session_state.keyword_mapping[g] = []
        save_keywords(st.session_state.keyword_mapping)
    st.session_state.new_group_input = ""

def add_sub(group):
    s = st.session_state.new_sub_input.strip()
    if s and s not in st.session_state.keyword_mapping[group]:
        st.session_state.keyword_mapping[group].append(s)
        save_keywords(st.session_state.keyword_mapping)
    st.session_state.new_sub_input = ""

with st.sidebar:
    st.title("ì§„ì£¼í–„ ë‰´ìŠ¤ë´‡")
    start_d, end_d = get_fixed_date_range()
    min_score = st.slider("ì—°ê´€ë„", 0, 5, 2)

    if st.button("ë‰´ìŠ¤ ìˆ˜ì§‘", use_container_width=True):
        st.session_state.news_results = collect_news_final(st.session_state.keyword_mapping, start_d, end_d)
        st.session_state.cart_list = []
        st.rerun()

    st.divider()
    st.subheader("í‚¤ì›Œë“œ ê´€ë¦¬")

    c1, c2 = st.columns(2)
    with c1:
        st.text_input("ëŒ€ë¶„ë¥˜ ì¶”ê°€", key="new_group_input", on_change=add_group)
    with c2:
        groups = list(st.session_state.keyword_mapping.keys())
        sel_g = st.selectbox("ì„ íƒ", groups) if groups else None

    if sel_g:
        st.text_input("í•˜ìœ„ í‚¤ì›Œë“œ ì¶”ê°€", key="new_sub_input", on_change=add_sub, args=(sel_g,))

    st.markdown("### ë“±ë¡ëœ í‚¤ì›Œë“œ")
    for g, subs in list(st.session_state.keyword_mapping.items()):
        with st.expander(f"{g} ({len(subs)})", expanded=True):
            c_del, _ = st.columns([0.15, 0.85])
            if c_del.button("ğŸ—‘ï¸ ëŒ€ë¶„ë¥˜ ì‚­ì œ", key=f"del_group_{g}"):
                del st.session_state.keyword_mapping[g]
                save_keywords(st.session_state.keyword_mapping)
                st.rerun()

            if not subs:
                st.caption("í•˜ìœ„ í‚¤ì›Œë“œ ì—†ìŒ")
            else:
                cols = st.columns(4)
                for i, s in enumerate(list(subs)):
                    if cols[i % 4].button(s, key=f"del_{g}_{s}", use_container_width=True):
                        st.session_state.keyword_mapping[g].remove(s)
                        save_keywords(st.session_state.keyword_mapping)
                        st.rerun()

st.title("Weekly News Clipping")
col_main, col_cart = st.columns([1.3, 0.7])

with col_main:
    tabs = ["ì „ì²´"] + list(st.session_state.keyword_mapping.keys())
    tab_objs = st.tabs(tabs)

    cart_links = [c["ë§í¬"] for c in st.session_state.cart_list]

    for i, tab in enumerate(tab_objs):
        with tab:
            cat = tabs[i]
            res = [r for r in st.session_state.news_results if r["ì—°ê´€ë„ì ìˆ˜"] >= min_score]
            if cat != "ì „ì²´":
                res = [r for r in res if r["í‚¤ì›Œë“œ"] == cat]

            with st.container(height=500):
                for idx, item in enumerate(res):
                    k = f"cb_{cat}_{idx}"
                    c1, c2 = st.columns([0.05, 0.95])
                    with c1:
                        st.checkbox("", key=k, value=item["ë§í¬"] in cart_links,
                                    on_change=toggle_cart_item, args=(item, k))
                    with c2:
                        st.markdown(f"**[{item['í‚¤ì›Œë“œ']}] {item['ì œëª©']}**")
                        st.caption(f"{item['ì¶œì²˜']} | {item['ê¸°ì‚¬ì¼ì']} | {item['ì—°ê´€ë„ì ìˆ˜']}ì ")

with col_cart:
    st.subheader("ì“¸ë§Œí•œ ë‰´ìŠ¤ ì¥ë°”êµ¬ë‹ˆ")
    if st.session_state.cart_list:
        df = pd.DataFrame(st.session_state.cart_list)
        st.dataframe(df[["í‚¤ì›Œë“œ", "ì¶œì²˜", "ê¸°ì‚¬ì¼ì", "ì œëª©"]],
                     use_container_width=True, hide_index=True, height=300)
        st.download_button(
            "ì—‘ì…€ ë‹¤ìš´ë¡œë“œ",
            to_excel(st.session_state.cart_list),
            file_name=f"ì§„ì£¼í–„_ë‰´ìŠ¤í´ë¦¬í•‘_{end_d.strftime('%Y%m%d')}.xlsx",
            use_container_width=True
        )
    else:
        st.info("ì„ íƒëœ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
