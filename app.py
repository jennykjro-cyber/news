import streamlit as st
import pandas as pd
from gnews import GNews
from datetime import datetime, timedelta
from io import BytesIO
import json
import os

# =================================================
# 1. ì‹œìŠ¤í…œ ì´ˆê¸° ì„¤ì • ë° ë°ì´í„° ë¡œë“œ
# =================================================
DB_FILE = "keywords_db.json"

def load_keywords():
    if os.path.exists(DB_FILE):
        try:
            with open(DB_FILE, "r", encoding="utf-8") as f:
                return json.load(f)
        except:
            pass
    return {
        "ìœ í†µ": ["í™ˆí”ŒëŸ¬ìŠ¤", "ì´ë§ˆíŠ¸", "ë¡¯ë°ë§ˆíŠ¸"],
        "í¸ì˜ì ": ["GS25", "CU"],
        "ìœ¡ê°€ê³µ": ["ìœ¡ê°€ê³µ", "í–„", "ì†Œì‹œì§€", "ë¹„ì—”ë‚˜"],
        "HMR": ["HMR", "ë°€í‚¤íŠ¸"],
        "ëŒ€ì²´ìœ¡": ["ëŒ€ì²´ìœ¡", "ì‹ë¬¼ì„±"],
        "ì‹œì¥ë™í–¥": ["ê°€ê²©ì¸ìƒ", "ì›ê°€", "ë¬¼ê°€", "ì‹í’ˆ ë§¤ì¶œ"]
    }

def save_keywords(mapping):
    with open(DB_FILE, "w", encoding="utf-8") as f:
        json.dump(mapping, f, ensure_ascii=False, indent=4)

if "keyword_mapping" not in st.session_state:
    st.session_state.keyword_mapping = load_keywords()
if "news_results" not in st.session_state:
    st.session_state.news_results = []
if "cart_list" not in st.session_state:
    st.session_state.cart_list = []

# =================================================
# 2. í•µì‹¬ ë¡œì§
# =================================================
def get_fixed_date_range():
    today = datetime.today()
    days_since_friday = (today.weekday() - 4) % 7
    last_friday = today - timedelta(days=days_since_friday)
    return last_friday.date(), today.date()

def parse_news_date(date_str):
    try:
        return datetime.strptime(date_str, "%a, %d %b %Y %H:%M:%S %Z").date()
    except:
        return None

def get_relevance_score(title, desc, all_keywords):
    score = 0
    text = f"{title} {desc}".replace(" ", "").lower()
    title_only = title.replace(" ", "").lower()
    for kw in all_keywords:
        t = kw.replace(" ", "").lower()
        if t in title_only:
            score += 2
        elif t in text:
            score += 1
    return score

def collect_news_final(mapping, start_date, end_date):
    google_news = GNews(language="ko", country="KR", max_results=25)
    all_rows = []
    all_search_kws = [kw for sub in mapping.values() for kw in sub]
    exclude_keywords = ["ì¶œì‹œ", "ëŸ°ì¹­", "ì‹ ì œí’ˆ", "ì´ë²¤íŠ¸", "ì¦ì •", "í• ì¸í–‰ì‚¬", "í¬í† ì¡´", "íŒì—…ìŠ¤í† ì–´", "ì¦ì‹œ", "ì£¼ê°€"]

    for group, sub_kws in mapping.items():
        if not sub_kws:
            continue

        search_query = f"{group} ({' OR '.join(sub_kws)})"
        articles = google_news.get_news(search_query)

        for a in articles:
            title = a.get("title", "ì œëª© ì—†ìŒ")
            if any(ex in title for ex in exclude_keywords):
                continue

            article_date = parse_news_date(a.get("published date", ""))
            if not article_date or not (start_date <= article_date <= end_date):
                continue

            desc = a.get("description", "")
            score = get_relevance_score(title, desc, all_search_kws)

            all_rows.append({
                "í‚¤ì›Œë“œ": group,
                "ì¶œì²˜": a.get("publisher", {}).get("title", "ì¶œì²˜ ë¯¸ìƒ"),
                "ê¸°ì‚¬ì¼ì": article_date.strftime("%Y-%m-%d"),
                "ì œëª©": title,
                "ë§í¬": a.get("url", ""),
                "ì—°ê´€ë„ì ìˆ˜": score
            })

    unique_rows = {r['ë§í¬']: r for r in all_rows}.values()
    return sorted(list(unique_rows), key=lambda x: x['ì—°ê´€ë„ì ìˆ˜'], reverse=True)

def to_excel(data_list):
    df = pd.DataFrame(data_list)
    output = BytesIO()
    with pd.ExcelWriter(output, engine="xlsxwriter") as writer:
        if not df.empty:
            export_df = df[["í‚¤ì›Œë“œ", "ì¶œì²˜", "ê¸°ì‚¬ì¼ì", "ì œëª©"]]
            export_df.to_excel(writer, index=False, sheet_name="ë‰´ìŠ¤í´ë¦¬í•‘")
        else:
            pd.DataFrame().to_excel(writer, sheet_name="ë‰´ìŠ¤í´ë¦¬í•‘")
    return output.getvalue()

# =================================================
# 3. UI
# =================================================
st.set_page_config(page_title="ì§„ì£¼í–„ ë‰´ìŠ¤ í´ë¦¬í•‘", page_icon="ğŸ¥“", layout="wide")

# ---------- ì‚¬ì´ë“œë°” ----------
with st.sidebar:
    st.title("ğŸ¥“ ì§„ì£¼í–„ ë‰´ìŠ¤ë´‡")
    st.subheader("ğŸ“ í‚¤ì›Œë“œ ê´€ë¦¬ì‹¤")

    # ê³ ì • ë†’ì´ + ë‚´ë¶€ ìŠ¤í¬ë¡¤
    with st.container(height=420):
        for cat in list(st.session_state.keyword_mapping.keys()):
            st.markdown(f"**{cat}**")
            for kw in list(st.session_state.keyword_mapping[cat]):
                c1, c2, c3 = st.columns([0.55, 0.3, 0.15])

                with c1:
                    st.write(kw)

                with c2:
                    move_to = st.selectbox(
                        "ì´ë™",
                        list(st.session_state.keyword_mapping.keys()),
                        index=list(st.session_state.keyword_mapping.keys()).index(cat),
                        key=f"move_{cat}_{kw}"
                    )
                    if move_to != cat:
                        st.session_state.keyword_mapping[cat].remove(kw)
                        st.session_state.keyword_mapping[move_to].append(kw)
                        save_keywords(st.session_state.keyword_mapping)
                        st.rerun()

                with c3:
                    if st.button("âŒ", key=f"del_{cat}_{kw}"):
                        st.session_state.keyword_mapping[cat].remove(kw)
                        save_keywords(st.session_state.keyword_mapping)
                        st.rerun()

    st.divider()

    # ëŒ€ë¶„ë¥˜ ì¶”ê°€
    new_cat = st.text_input("ëŒ€ë¶„ë¥˜ ì…ë ¥ í›„ Enter", key="new_cat")
    if new_cat:
        st.session_state.keyword_mapping.setdefault(new_cat, [])
        save_keywords(st.session_state.keyword_mapping)
        st.session_state.new_cat = ""
        st.rerun()

    # í‚¤ì›Œë“œ ì¶”ê°€
    target_cat = st.selectbox("í‚¤ì›Œë“œ ì¶”ê°€ ìœ„ì¹˜", st.session_state.keyword_mapping.keys())
    new_kw = st.text_input("í‚¤ì›Œë“œ ì…ë ¥ í›„ Enter", key="new_kw")
    if new_kw:
        st.session_state.keyword_mapping[target_cat].append(new_kw)
        save_keywords(st.session_state.keyword_mapping)
        st.session_state.new_kw = ""
        st.rerun()

# ---------- ë©”ì¸ ----------
start_d, end_d = get_fixed_date_range()

if st.button("ğŸ—‚ ì´ë²ˆ ì£¼ ì–´ì©” ìˆ˜ ì—†ëŠ” ë‰´ìŠ¤ ìˆ˜ì§‘"):
    st.session_state.news_results = collect_news_final(
        st.session_state.keyword_mapping, start_d, end_d
    )
    st.session_state.cart_list = []

col_main, col_cart = st.columns([1.3, 0.7])

with col_main:
    for item in st.session_state.news_results:
        if st.checkbox(item["ì œëª©"], key=item["ë§í¬"]):
            if item not in st.session_state.cart_list:
                st.session_state.cart_list.append(item)

with col_cart:
    st.subheader("ğŸ›’ ì“¸ë§Œí•œ ë‰´ìŠ¤ ì¥ë°”êµ¬ë‹ˆ")

    if st.session_state.cart_list:
        cart_df = pd.DataFrame(st.session_state.cart_list)
        st.dataframe(
            cart_df[["í‚¤ì›Œë“œ", "ì¶œì²˜", "ê¸°ì‚¬ì¼ì", "ì œëª©"]],
            use_container_width=True,
            hide_index=True
        )

        st.download_button(
            "ğŸ“¥ ì—‘ì…€ ë‹¤ìš´ë¡œë“œ",
            to_excel(st.session_state.cart_list),
            "ì§„ì£¼í–„_ë‰´ìŠ¤í´ë¦¬í•‘.xlsx",
            use_container_width=True
        )
    else:
        st.info("ì•„ì§ ì“¸ë§Œí•œ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
