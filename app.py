import streamlit as st
import pandas as pd
from gnews import GNews
from datetime import datetime, timedelta
from io import BytesIO
import json
import os

# =================================================
# 1. ì‹œìŠ¤í…œ ì´ˆê¸° ì„¤ì • ë° ë°ì´í„° ë¡œë“œ
# =================================================
DB_FILE = "keywords_db.json"

def load_keywords():
    if os.path.exists(DB_FILE):
        try:
            with open(DB_FILE, "r", encoding="utf-8") as f:
                return json.load(f)
        except:
            pass
    return {
        "ìœ í†µ": ["í™ˆí”ŒëŸ¬ìŠ¤", "ì´ë§ˆíŠ¸", "ë¡¯ë°ë§ˆíŠ¸"],
        "í¸ì˜ì ": ["GS25", "CU"],
        "ìœ¡ê°€ê³µ": ["ìœ¡ê°€ê³µ", "í–„", "ì†Œì‹œì§€", "ë¹„ì—”ë‚˜"],
        "HMR": ["HMR", "ë°€í‚¤íŠ¸"],
        "ëŒ€ì²´ìœ¡": ["ëŒ€ì²´ìœ¡", "ì‹ë¬¼ì„±"],
        "ì‹œì¥ë™í–¥": ["ê°€ê²©ì¸ìƒ", "ì›ê°€", "ë¬¼ê°€", "ì‹í’ˆ ë§¤ì¶œ"]
    }

def save_keywords(mapping):
    with open(DB_FILE, "w", encoding="utf-8") as f:
        json.dump(mapping, f, ensure_ascii=False, indent=4)

if "keyword_mapping" not in st.session_state:
    st.session_state.keyword_mapping = load_keywords()
if "news_results" not in st.session_state:
    st.session_state.news_results = []
if "cart_list" not in st.session_state:
    st.session_state.cart_list = []

# =================================================
# 2. í•µì‹¬ ë¡œì§
# =================================================
def get_fixed_date_range():
    today = datetime.today()
    days_since_friday = (today.weekday() - 4) % 7
    last_friday = today - timedelta(days=days_since_friday)
    return last_friday.date(), today.date()

def parse_news_date(date_str):
    try: return datetime.strptime(date_str, "%a, %d %b %Y %H:%M:%S %Z").date()
    except: return None

def get_relevance_score(title, desc, all_keywords):
    score = 0
    text = f"{title} {desc}".replace(" ", "").lower()
    title_only = title.replace(" ", "").lower()
    for kw in all_keywords:
        target = kw.replace(" ", "").lower()
        if target in title_only: score += 2
        elif target in text: score += 1
    return score

def collect_news_final(mapping, start_date, end_date):
    google_news = GNews(language="ko", country="KR", max_results=25)
    all_rows = []
    all_search_kws = [kw for sublist in mapping.values() for kw in sublist]
    exclude_keywords = ["ì¶œì‹œ", "ëŸ°ì¹­", "ì‹ ì œí’ˆ", "ì´ë²¤íŠ¸", "ì¦ì •", "í• ì¸í–‰ì‚¬", "í¬í† ì¡´", "íŒì—…ìŠ¤í† ì–´", "ì¦ì‹œ", "ì£¼ê°€", "ìƒí•œê°€"]
    progress_bar = st.progress(0)
    groups = list(mapping.items())
    for i, (group, sub_kws) in enumerate(groups):
        if not sub_kws: continue
        articles = google_news.get_news(f"{group} ({' OR '.join(sub_kws)})")
        for a in articles:
            title = a.get("title", "ì œëª© ì—†ìŒ")
            if any(ex in title for ex in exclude_keywords): continue
            article_date = parse_news_date(a.get("published date", ""))
            if not article_date or not (start_date <= article_date <= end_date): continue
            score = get_relevance_score(title, a.get("description", ""), all_search_kws)
            all_rows.append({"í‚¤ì›Œë“œ": group, "ì¶œì²˜": a.get("publisher", {}).get("title", "ì¶œì²˜ ë¯¸ìƒ"), "ê¸°ì‚¬ì¼ì": article_date.strftime("%Y-%m-%d"), "ì œëª©": title, "ë§í¬": a.get("url", ""), "ì—°ê´€ë„ì ìˆ˜": score})
        progress_bar.progress((i + 1) / len(groups))
    unique_rows = {r['ë§í¬']: r for r in all_rows}.values()
    return sorted(list(unique_rows), key=lambda x: x['ì—°ê´€ë„ì ìˆ˜'], reverse=True)

def to_excel(data_list):
    df = pd.DataFrame(data_list)
    output = BytesIO()
    with pd.ExcelWriter(output, engine="xlsxwriter") as writer:
        df[["í‚¤ì›Œë“œ", "ì¶œì²˜", "ê¸°ì‚¬ì¼ì", "ì œëª©"]].to_excel(writer, index=False, sheet_name="ë‰´ìŠ¤í´ë¦¬í•‘")
        workbook, worksheet = writer.book, writer.sheets["ë‰´ìŠ¤í´ë¦¬í•‘"]
        link_format = workbook.add_format({'font_color': 'blue', 'underline': 1})
        for row_num, link in enumerate(df['ë§í¬']):
            worksheet.write_url(row_num + 1, 3, link, link_format, df.iloc[row_num]['ì œëª©'])
        worksheet.set_column('A:C', 15); worksheet.set_column('D:D', 80)
    return output.getvalue()

# =================================================
# 3. UI/UX
# =================================================
st.set_page_config(page_title="ì§„ì£¼í–„ ë‰´ìŠ¤ í´ë¦¬í•‘", page_icon="ğŸ¥“", layout="wide")

def toggle_cart_item(item, key):
    if st.session_state[key]:
        if item['ë§í¬'] not in [c['ë§í¬'] for c in st.session_state.cart_list]:
            st.session_state.cart_list.append(item)
    else:
        st.session_state.cart_list = [c for c in st.session_state.cart_list if c['ë§í¬'] != item['ë§í¬']]

def add_group():
    new_g = st.session_state.new_group_input.strip()
    if new_g and new_g not in st.session_state.keyword_mapping:
        st.session_state.keyword_mapping[new_g] = []; save_keywords(st.session_state.keyword_mapping)
    st.session_state.new_group_input = ""

def add_sub(group_name):
    new_s = st.session_state.new_sub_input.strip()
    if new_s and new_s not in st.session_state.keyword_mapping[group_name]:
        st.session_state.keyword_mapping[group_name].append(new_s); save_keywords(st.session_state.keyword_mapping)
    st.session_state.new_sub_input = ""

with st.sidebar:
    st.title("ğŸ¥“ ì§„ì£¼í–„ ë‰´ìŠ¤ë´‡")
    st.write("---")
    st.subheader("âš™ï¸ ê²€ìƒ‰ ì„¤ì •")
    start_d, end_d = get_fixed_date_range()
    st.info(f"ğŸ“… {start_d.strftime('%m.%d')} ~ {end_d.strftime('%m.%d')}")
    min_score = st.slider("ğŸ¯ ì—°ê´€ë„ í•„í„°", 0, 5, 2)
    if st.button("ğŸ—‚ ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹œì‘", type="primary", use_container_width=True):
        st.session_state.news_results = collect_news_final(st.session_state.keyword_mapping, start_d, end_d)
        st.session_state.cart_list = []; st.rerun()

    st.divider()
    # [ìˆ˜ì •] í‚¤ì›Œë“œ ê´€ë¦¬ì‹¤: expanded=False ë¡œ ì„¤ì •í•˜ì—¬ ê¸°ë³¸ì ìœ¼ë¡œ ì ‘ì–´ë‘ 
    with st.expander("ğŸ“ í‚¤ì›Œë“œ ê´€ë¦¬ì‹¤ (í´ë¦­í•˜ì—¬ ì—´ê¸°)", expanded=False):
        col1, col2 = st.columns(2)
        with col1: st.text_input("ëŒ€ë¶„ë¥˜", key="new_group_input", on_change=add_group, placeholder="ë¶„ë¥˜ëª…")
        with col2:
            keys = list(st.session_state.keyword_mapping.keys())
            sel_g = st.selectbox("ì„ íƒ", options=keys) if keys else st.selectbox("ì—†ìŒ", ["-"])
        if keys:
            st.text_input(f"â• '{sel_g}'ì— ì¶”ê°€", key="new_sub_input", on_change=add_sub, args=(sel_g,))
        
        st.markdown("---")
        with st.container(height=300, border=False):
            for g, subs in list(st.session_state.keyword_mapping.items()):
                c_t, c_d = st.columns([0.8, 0.2])
                c_t.markdown(f"**{g}**")
                if c_d.button("ğŸ—‘ï¸", key=f"del_g_{g}"):
                    del st.session_state.keyword_mapping[g]; save_keywords(st.session_state.keyword_mapping); st.rerun()
                
                kw_cols = st.columns(2)
                for idx, s in enumerate(subs):
                    with kw_cols[idx % 2]:
                        if st.button(f"{s} Ã—", key=f"del_kw_{g}_{s}", use_container_width=True):
                            st.session_state.keyword_mapping[g].remove(s); save_keywords(st.session_state.keyword_mapping); st.rerun()

# ë©”ì¸ í™”ë©´
st.title("ğŸ“° Weekly News Clipping")
col_main, col_cart = st.columns([1.3, 0.7])

with col_main:
    st.subheader("ğŸ” ê²€ìƒ‰ ê²°ê³¼")
    all_categories = ["ì „ì²´"] + list(st.session_state.keyword_mapping.keys())
    tabs = st.tabs([f" {cat} " for cat in all_categories])
    cart_links = [item['ë§í¬'] for item in st.session_state.cart_list]
    
    for i, tab in enumerate(tabs):
        with tab:
            current_cat = all_categories[i]
            filtered_res = [r for r in st.session_state.news_results if r.get('ì—°ê´€ë„ì ìˆ˜', 0) >= min_score]
            if current_cat != "ì „ì²´": filtered_res = [r for r in filtered_res if r['í‚¤ì›Œë“œ'] == current_cat]
            
            if filtered_res:
                st.success(f"ì´ {len(filtered_res)}ê±´ ë°œê²¬")
                # [ìˆ˜ì •] ë‰´ìŠ¤ ë¦¬ìŠ¤íŠ¸ ìŠ¤í¬ë¡¤: height=500 ì„¤ì •ìœ¼ë¡œ 5ê°œ ë‚´ì™¸ ìœ ì§€
                with st.container(height=550):
                    for idx, item in enumerate(filtered_res):
                        u_key = f"cb_{current_cat}_{idx}_{item['ë§í¬']}"
                        with st.container(border=True):
                            c_ch, c_tx = st.columns([0.05, 0.95])
                            c_ch.checkbox("", key=u_key, value=(item['ë§í¬'] in cart_links), on_change=toggle_cart_item, args=(item, u_key))
                            c_tx.markdown(f"**[{item['í‚¤ì›Œë“œ']}] {item['ì œëª©']}**")
                            c_tx.caption(f"ğŸ— {item['ì¶œì²˜']} | ğŸ—“ {item['ê¸°ì‚¬ì¼ì']} | â­ {item['ì—°ê´€ë„ì ìˆ˜']}ì ")
                            c_tx.markdown(f"[ğŸ”— ê¸°ì‚¬ ì›ë¬¸]({item['ë§í¬']})")
            else: st.info("ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")

with col_cart:
    st.subheader("ğŸ›’ ì¥ë°”êµ¬ë‹ˆ")
    if st.session_state.cart_list:
        with st.container(border=True):
            st.dataframe(pd.DataFrame(st.session_state.cart_list)[["í‚¤ì›Œë“œ", "ì œëª©"]], use_container_width=True, hide_index=True, height=300)
            st.download_button(label="ğŸ“¥ ì—‘ì…€ ë‹¤ìš´ë¡œë“œ", data=to_excel(st.session_state.cart_list), file_name=f"ë‰´ìŠ¤í´ë¦¬í•‘_{datetime.now().strftime('%Y%m%d')}.xlsx", mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet", use_container_width=True, type="primary")
            if st.button("ğŸ”„ ì´ˆê¸°í™”", use_container_width=True):
                st.session_state.cart_list = []; st.rerun()
    else: st.info("ê¸°ì‚¬ë¥¼ ë‹´ì•„ì£¼ì„¸ìš”.")
