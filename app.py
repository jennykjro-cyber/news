import streamlit as st
import pandas as pd
from gnews import GNews
from datetime import datetime, timedelta
from io import BytesIO

# =================================================
# 1. ì„¤ì • ë° ì„¸ì…˜ ì´ˆê¸°í™”
# =================================================
BUSINESS_KEYWORDS = [
    "ìœ¡ê°€ê³µ", "í–„", "ì†Œì‹œì§€", "ì‹í’ˆ", "ì›ê°€", "ê°€ê²©ì¸ìƒ",
    "ì‹í’ˆ ë§ˆì¼€íŒ…", "ìœ í†µ", "í¸ì˜ì  ì‹ ì œí’ˆ", "ëŒ€ì²´ìœ¡", "HMR"
]

# ìœ„ì ¯ ì´ˆê¸°í™”ë¥¼ ìœ„í•œ ë²„ì „ ê´€ë¦¬ í‚¤ ì¶”ê°€
if "reset_key" not in st.session_state:
    st.session_state.reset_key = 0
if "news_results" not in st.session_state:
    st.session_state.news_results = [] 
if "cart" not in st.session_state:
    st.session_state.cart = pd.DataFrame()

google_news = GNews(language="ko", country="KR", max_results=20)

# =================================================
# 2. ê¸°ëŠ¥ í•¨ìˆ˜
# =================================================
def get_fixed_date_range():
    today = datetime.today()
    this_thursday = today - timedelta(days=(today.weekday() - 3) % 7)
    last_friday = this_thursday - timedelta(days=6)
    return last_friday.date(), this_thursday.date()

def parse_news_date(date_str):
    try:
        return datetime.strptime(date_str, "%a, %d %b %Y %H:%M:%S %Z").date()
    except:
        return None

def relevance_score(text: str) -> int:
    return sum(1 for kw in BUSINESS_KEYWORDS if kw.replace(" ", "") in text.replace(" ", ""))

def collect_all_news(start_date, end_date):
    all_rows = []
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    for i, kw in enumerate(BUSINESS_KEYWORDS):
        status_text.text(f"ğŸ” '{kw}' ë‰´ìŠ¤ ìˆ˜ì§‘ ì¤‘... ({i+1}/{len(BUSINESS_KEYWORDS)})")
        articles = google_news.get_news(kw)
        for a in articles:
            article_date = parse_news_date(a.get("published date", ""))
            if article_date is None or not (start_date <= article_date <= end_date):
                continue
            title = a.get("title", "")
            all_rows.append({
                "ê²€ìƒ‰í‚¤ì›Œë“œ": kw,
                "ì¶œì²˜": a.get("publisher", {}).get("title", ""),
                "ê¸°ì‚¬ì¼ì": article_date.strftime("%Y-%m-%d"),
                "ì œëª©": title,
                "ë§í¬": a.get("url", ""),
                "ì—°ê´€ë„ì ìˆ˜": relevance_score(f"{title} {a.get('description', '')}")
            })
        progress_bar.progress((i + 1) / len(BUSINESS_KEYWORDS))
    
    status_text.text("âœ… ìˆ˜ì§‘ ì™„ë£Œ!")
    df = pd.DataFrame(all_rows).drop_duplicates(subset=["ë§í¬"])
    return df.to_dict('records')

def to_excel(df: pd.DataFrame):
    output = BytesIO()
    with pd.ExcelWriter(output, engine="xlsxwriter") as writer:
        export_df = df[["ê²€ìƒ‰í‚¤ì›Œë“œ", "ì¶œì²˜", "ê¸°ì‚¬ì¼ì", "ì œëª©"]]
        export_df.to_excel(writer, index=False, sheet_name="ë‰´ìŠ¤í´ë¦¬í•‘")
        workbook  = writer.book
        worksheet = writer.sheets["ë‰´ìŠ¤í´ë¦¬í•‘"]
        link_format = workbook.add_format({'font_color': 'blue', 'underline': 1})

        for row_num, (index, row) in enumerate(df.iterrows()):
            # ì—‘ì…€ ë³µêµ¬ ì˜¤ë¥˜ ë°©ì§€ë¥¼ ìœ„í•´ write_url ì§ì ‘ ì‚¬ìš©
            worksheet.write_url(row_num + 1, 3, row['ë§í¬'], link_format, row['ì œëª©'])
            
        worksheet.set_column('A:C', 15)
        worksheet.set_column('D:D', 80)
    return output.getvalue()

# =================================================
# 3. UI í™”ë©´ êµ¬ì„±
# =================================================
st.set_page_config(page_title="ì£¼ê°„ ë‰´ìŠ¤ í´ë¦¬í•‘", layout="wide")
st.title("ğŸš€ ì£¼ê°„ ë‰´ìŠ¤ í´ë¦¬í•‘ ìë™í™”")

start_date, end_date = get_fixed_date_range()
st.success(f"ğŸ“… ìˆ˜ì§‘ ê¸°ì¤€ì¼: **{start_date} (ê¸ˆ) ~ {end_date} (ëª©)**")

with st.sidebar:
    st.header("âš™ï¸ í•„í„° ì„¤ì •")
    min_score = st.slider("ì—…ë¬´ ì—°ê´€ë„ í•„í„°", 0, 5, 1)
    
    if st.button("ğŸŒŸ ë‰´ìŠ¤í´ë¦¬í•‘ ì‹œì‘", use_container_width=True, type="primary"):
        results = collect_all_news(start_date, end_date)
        st.session_state.news_results = [r for r in results if r['ì—°ê´€ë„ì ìˆ˜'] >= min_score]
        st.session_state.cart = pd.DataFrame() # ìƒˆ ê²€ìƒ‰ ì‹œ ì¥ë°”êµ¬ë‹ˆ ì´ˆê¸°í™”

# ë©”ì¸ ë ˆì´ì•„ì›ƒ
col1, col2 = st.columns([1.2, 0.8])

with col1:
    st.subheader("ğŸ“Œ ìˆ˜ì§‘ëœ ë‰´ìŠ¤ ë¦¬ìŠ¤íŠ¸")
    if st.session_state.news_results:
        temp_selected = []
        for idx, item in enumerate(st.session_state.news_results):
            # reset_keyë¥¼ ê²°í•©í•˜ì—¬ ë²„íŠ¼ í´ë¦­ ì‹œ ì²´í¬ë°•ìŠ¤ë¥¼ ê°•ì œë¡œ ë‹¤ì‹œ ê·¸ë¦¬ê²Œ í•¨ (ì—ëŸ¬ ë°©ì§€ í•µì‹¬)
            cb_key = f"news_{idx}_v{st.session_state.reset_key}"
            if st.checkbox(f"[{item['ì¶œì²˜']}] {item['ì œëª©']}", key=cb_key):
                temp_selected.append(item)
        st.session_state.cart = pd.DataFrame(temp_selected)
    else:
        st.write("ì‚¬ì´ë“œë°”ì˜ ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.")

with col2:
    st.subheader("ğŸ›’ ì¥ë°”êµ¬ë‹ˆ (ì¶”ì¶œ ëª©ë¡)")
    if not st.session_state.cart.empty:
        st.dataframe(st.session_state.cart[["ì¶œì²˜", "ì œëª©"]], use_container_width=True, hide_index=True)
        
        excel_data = to_excel(st.session_state.cart)
        st.download_button(
            label="ğŸ“¥ ì—‘ì…€ íŒŒì¼ ë‹¤ìš´ë¡œë“œ",
            data=excel_data,
            file_name=f"ë‰´ìŠ¤í´ë¦¬í•‘_{end_date}.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            use_container_width=True
        )
        
        # ì „ì²´ í•´ì œ ê¸°ëŠ¥ì„ ì•ˆì „í•˜ê²Œ êµ¬í˜„
        if st.button("ğŸ”„ ì„ íƒ ì „ì²´ í•´ì œ", use_container_width=True):
            st.session_state.reset_key += 1 # í‚¤ ê°’ì„ ë°”ê¿”ì„œ ìœ„ì ¯ì„ ì™„ì „íˆ ìƒˆë¡œ ê³ ì¹¨
            st.session_state.cart = pd.DataFrame()
            st.rerun()
    else:
        st.info("ì„ íƒëœ ê¸°ì‚¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
