import streamlit as st
import pandas as pd
from gnews import GNews
from datetime import datetime, timedelta
from io import BytesIO
import json
import os

# =================================================
# 1. í‚¤ì›Œë“œ DB ê´€ë¦¬ (JSON ê¸°ë°˜)
# =================================================
DB_FILE = "keywords_db.json"

def load_keywords():
    if os.path.exists(DB_FILE):
        try:
            with open(DB_FILE, "r", encoding="utf-8") as f:
                return json.load(f)
        except:
            pass
    return {
        "ìœ í†µ": ["í™ˆí”ŒëŸ¬ìŠ¤", "ì´ë§ˆíŠ¸", "ë¡¯ë°ë§ˆíŠ¸"],
        "í¸ì˜ì ": ["GS25", "CU"],
        "ìœ¡ê°€ê³µ": ["ìœ¡ê°€ê³µ", "í–„", "ì†Œì‹œì§€", "ë¹„ì—”ë‚˜"],
        "HMR": ["HMR", "ë°€í‚¤íŠ¸"],
        "ëŒ€ì²´ìœ¡": ["ëŒ€ì²´ìœ¡", "ì‹ë¬¼ì„±"],
        "ì‹œì¥ë™í–¥": ["ê°€ê²©ì¸ìƒ", "ì›ê°€", "ë¬¼ê°€", "ì‹í’ˆ ë§¤ì¶œ"]
    }

def save_keywords(mapping):
    with open(DB_FILE, "w", encoding="utf-8") as f:
        json.dump(mapping, f, ensure_ascii=False, indent=4)

if "keyword_mapping" not in st.session_state:
    st.session_state.keyword_mapping = load_keywords()
if "reset_key" not in st.session_state:
    st.session_state.reset_key = 0
if "news_results" not in st.session_state:
    st.session_state.news_results = []
if "cart" not in st.session_state:
    st.session_state.cart = pd.DataFrame()

# =================================================
# 2. ê³ ë„í™”ëœ ì—°ê´€ë„ ê³„ì‚° ë° ìˆ˜ì§‘ ë¡œì§
# =================================================
def get_relevance_score(title, desc, all_keywords):
    """
    ì œëª©ì— í‚¤ì›Œë“œê°€ ìˆìœ¼ë©´ 2ì , ë³¸ë¬¸ì— ìˆìœ¼ë©´ 1ì ì„ ë¶€ì—¬í•˜ì—¬ 
    ì ìˆ˜ê°€ ë” ì˜ ë‚˜ì˜¤ë„ë¡ ê°€ì¤‘ì¹˜ë¥¼ ë‘¡ë‹ˆë‹¤.
    """
    score = 0
    full_text = f"{title} {desc}".replace(" ", "").lower()
    title_text = title.replace(" ", "").lower()
    
    for kw in all_keywords:
        target = kw.replace(" ", "").lower()
        if target in title_text:
            score += 2  # ì œëª© ë§¤ì¹­ ê°€ì¤‘ì¹˜
        elif target in full_text:
            score += 1
    return score

def collect_news_enhanced(mapping, start_date, end_date):
    google_news = GNews(language="ko", country="KR", max_results=15)
    all_rows = []
    
    # ì „ì²´ í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸ (ì ìˆ˜ ê³„ì‚°ìš©)
    all_search_kws = [kw for sublist in mapping.values() for kw in sublist]
    
    # ì§„í–‰ ìƒí™© í‘œì‹œ
    progress_bar = st.progress(0)
    total_groups = len(mapping)
    
    for i, (group, sub_kws) in enumerate(mapping.items()):
        for kw in sub_kws:
            articles = google_news.get_news(kw)
            for a in articles:
                pub_date = a.get("published date", "")
                article_date = None
                try:
                    article_date = datetime.strptime(pub_date, "%a, %d %b %Y %H:%M:%S %Z").date()
                except: continue
                
                if not (start_date <= article_date <= end_date):
                    continue
                
                title = a.get("title", "")
                desc = a.get("description", "")
                
                # ì ìˆ˜ ê³„ì‚° ì‹¤í–‰
                score = get_relevance_score(title, desc, all_search_kws)
                
                all_rows.append({
                    "ê·¸ë£¹": group,
                    "ì¶œì²˜": a.get("publisher", {}).get("title", ""),
                    "ê¸°ì‚¬ì¼ì": article_date.strftime("%Y-%m-%d"),
                    "ì œëª©": title,
                    "ë§í¬": a.get("url", ""),
                    "ì—°ê´€ë„ì ìˆ˜": score
                })
        progress_bar.progress((i + 1) / total_groups)
    
    df = pd.DataFrame(all_rows).drop_duplicates(subset=["ë§í¬"])
    return df.to_dict('records')

# =================================================
# 3. í™”ë©´ UI
# =================================================
st.set_page_config(page_title="ì£¼ê°„ ë‰´ìŠ¤ í´ë¦¬í•‘", layout="wide")

# --- í‚¤ì›Œë“œ ê´€ë¦¬ ì„¹ì…˜ ---
with st.expander("ğŸ› ï¸ ë‰´ìŠ¤í´ë¦¬í•‘ í‚¤ì›Œë“œ ê´€ë¦¬ (í´ë¦­í•˜ì—¬ ì—´ê¸°)", expanded=False):
    st.info("ì—¬ê¸°ì„œ ìˆ˜ì •í•œ í‚¤ì›Œë“œëŠ” íŒŒì¼ì— ì €ì¥ë˜ì–´ ê³„ì† ìœ ì§€ë©ë‹ˆë‹¤.")
    
    c1, c2 = st.columns(2)
    with c1:
        new_g = st.text_input("ìƒˆ ëŒ€ë¶„ë¥˜")
        if st.button("ëŒ€ë¶„ë¥˜ ì¶”ê°€"):
            if new_g and new_g not in st.session_state.keyword_mapping:
                st.session_state.keyword_mapping[new_g] = []
                save_keywords(st.session_state.keyword_mapping)
                st.rerun()
    with c2:
        sel_g = st.selectbox("ì†Œë¶„ë¥˜ ì¶”ê°€í•  ê³³", options=list(st.session_state.keyword_mapping.keys()))
        new_s = st.text_input("ìƒˆ ì†Œë¶„ë¥˜ í‚¤ì›Œë“œ")
        if st.button("ì†Œë¶„ë¥˜ ì¶”ê°€"):
            if new_s and new_s not in st.session_state.keyword_mapping[sel_g]:
                st.session_state.keyword_mapping[sel_g].append(new_s)
                save_keywords(st.session_state.keyword_mapping)
                st.rerun()
    
    st.write("---")
    # í˜„ì¬ í‚¤ì›Œë“œ ì‚­ì œ ë° ë³´ê¸°
    for g, subs in list(st.session_state.keyword_mapping.items()):
        col_g, col_s = st.columns([1, 4])
        with col_g:
            if st.button(f"ğŸ—‘ï¸ {g} ì‚­ì œ", key=f"del_{g}"):
                del st.session_state.keyword_mapping[g]
                save_keywords(st.session_state.keyword_mapping)
                st.rerun()
        with col_s:
            st.write(f"**{g}**: {', '.join(subs)}")

# --- ë‰´ìŠ¤ ìˆ˜ì§‘ ì„¹ì…˜ ---
st.title("ğŸš€ ì£¼ê°„ ë‰´ìŠ¤ í´ë¦¬í•‘ ì‹œìŠ¤í…œ")
start_d, end_d = get_fixed_date_range() # ê¸°ì¡´ ë‚ ì§œ í•¨ìˆ˜ ì‚¬ìš©
st.success(f"ğŸ“… ëŒ€ìƒ ê¸°ê°„: {start_d} ~ {end_d}")

with st.sidebar:
    st.header("âš™ï¸ ê²€ìƒ‰ í•„í„°")
    # ì ìˆ˜ê°€ ë” ì˜ ë‚˜ì˜¤ë„ë¡ ê°€ì¤‘ì¹˜ë¥¼ ì¤¬ìœ¼ë¯€ë¡œ ìŠ¬ë¼ì´ë” ë²”ìœ„ë¥¼ ìœ ì§€í•©ë‹ˆë‹¤.
    min_score = st.slider("ì—…ë¬´ ì—°ê´€ë„ í•„í„° (ì ìˆ˜â†‘ = ê´€ë ¨ì„±â†‘)", 0, 10, 3)
    
    if st.button("ğŸŒŸ ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹œì‘", type="primary", use_container_width=True):
        st.session_state.news_results = collect_news_enhanced(st.session_state.keyword_mapping, start_d, end_d)
        st.session_state.cart = pd.DataFrame()
        st.rerun()

# --- ê²°ê³¼ ì¶œë ¥ ---
col_list, col_cart = st.columns([1.2, 0.8])

with col_list:
    st.subheader("ğŸ“Œ ë‰´ìŠ¤ ë¦¬ìŠ¤íŠ¸")
    # í•„í„°ë§ ì ìš©
    res = [r for r in st.session_state.news_results if r['ì—°ê´€ë„ì ìˆ˜'] >= min_score]
    
    if res:
        for idx, item in enumerate(res):
            k = f"chk_{idx}_v{st.session_state.reset_key}"
            if st.checkbox(f"[{item['ê·¸ë£¹']} | ì ìˆ˜:{item['ì—°ê´€ë„ì ìˆ˜']}] {item['ì œëª©']}", key=k):
                # ì¥ë°”êµ¬ë‹ˆ ì¶”ê°€ ë¡œì§ (ê¸°ì¡´ê³¼ ë™ì¼)
                if item['ë§í¬'] not in st.session_state.cart.values:
                    st.session_state.cart = pd.concat([st.session_state.cart, pd.DataFrame([item])])
    elif st.session_state.news_results:
        st.warning(f"ì ìˆ˜ {min_score}ì  ì´ìƒ ê¸°ì‚¬ê°€ ì—†ìŠµë‹ˆë‹¤. í•„í„°ë¥¼ ë‚®ì¶”ê±°ë‚˜ í‚¤ì›Œë“œë¥¼ ì ê²€í•˜ì„¸ìš”.")

with col_cart:
    st.subheader("ğŸ›’ ì¶”ì¶œ ë°”êµ¬ë‹ˆ")
    if not st.session_state.cart.empty:
        st.dataframe(st.session_state.cart[["ê·¸ë£¹", "ì œëª©", "ì—°ê´€ë„ì ìˆ˜"]], hide_index=True)
        # ì—‘ì…€ ë‹¤ìš´ë¡œë“œ (ê¸°ì¡´ xlsxwriter í•¨ìˆ˜ ì‚¬ìš©)
        if st.button("ğŸ”„ ì „ì²´ í•´ì œ"):
            st.session_state.reset_key += 1
            st.session_state.cart = pd.DataFrame()
            st.rerun()
