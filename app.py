import streamlit as st
import pandas as pd
from gnews import GNews
from datetime import datetime, timedelta
from io import BytesIO

# =================================================
# 1. ì„¤ì • ë° ì„¸ì…˜ ì´ˆê¸°í™”
# =================================================
BUSINESS_KEYWORDS = [
    "ìœ¡ê°€ê³µ", "í–„", "ì†Œì‹œì§€", "ì‹í’ˆ", "ì›ê°€", "ê°€ê²©", "ê°€ê²©ì¸ìƒ",
    "ë§ˆì¼€íŒ…", "ë¸Œëœë“œ", "ìœ í†µ", "í¸ì˜ì ", "ëŒ€ì²´ìœ¡", "ì‹œì¥", "ë§¤ì¶œ"
]

if "news_results" not in st.session_state:
    st.session_state.news_results = [] 
if "cart" not in st.session_state:
    st.session_state.cart = pd.DataFrame()

google_news = GNews(language="ko", country="KR", max_results=50)

# =================================================
# 2. ê¸°ëŠ¥ í•¨ìˆ˜ (ë‚ ì§œ, ê²€ìƒ‰, ì ìˆ˜)
# =================================================
def get_date_range():
    today = datetime.today()
    this_thursday = today - timedelta(days=(today.weekday() - 3) % 7)
    last_saturday = this_thursday - timedelta(days=5)
    return last_saturday.date(), this_thursday.date()

def parse_news_date(date_str):
    try:
        return datetime.strptime(date_str, "%a, %d %b %Y %H:%M:%S %Z").date()
    except:
        return None

def relevance_score(text: str) -> int:
    return sum(1 for kw in BUSINESS_KEYWORDS if kw in text)

def collect_news(keyword: str, start_date, end_date):
    articles = google_news.get_news(keyword)
    rows = []
    for a in articles:
        article_date = parse_news_date(a.get("published date", ""))
        if article_date is None or not (start_date <= article_date <= end_date):
            continue
        
        title = a.get("title", "")
        score = relevance_score(f"{title} {a.get('description', '')}")
        
        rows.append({
            "ê²€ìƒ‰í‚¤ì›Œë“œ": keyword,
            "ì¶œì²˜": a.get("publisher", {}).get("title", ""),
            "ê¸°ì‚¬ì¼ì": article_date.strftime("%Y-%m-%d"),
            "ì œëª©": title,
            "ë§í¬": a.get("url", ""),
            "ì—°ê´€ë„ì ìˆ˜": score
        })
    return rows

# [ì˜¤ë¥˜ ìˆ˜ì • í•µì‹¬] ì—‘ì…€ ë³€í™˜ í•¨ìˆ˜
def to_excel(df: pd.DataFrame):
    output = BytesIO()
    df_safe = df.copy()
    
    # ì—‘ì…€ ìˆ˜ì‹ ì˜¤ë¥˜ì˜ ì£¼ë²”ì¸ í°ë”°ì˜´í‘œ(")ë¥¼ ì œê±°í•˜ê±°ë‚˜ ì¹˜í™˜
    df_safe["ì œëª©_í´ë¦°"] = df_safe["ì œëª©"].str.replace('"', "'")
    
    # í•˜ì´í¼ë§í¬ ìˆ˜ì‹ ì ìš©
    df_safe["ê¸°ì‚¬ì œëª©(ë§í¬)"] = df_safe.apply(
        lambda x: f'=HYPERLINK("{x["ë§í¬"]}", "{x["ì œëª©_í´ë¦°"]}")', axis=1
    )
    
    # ìµœì¢… íŒŒì¼ì— í¬í•¨í•  ì»¬ëŸ¼ë§Œ ì„ íƒ
    export_df = df_safe[["ê²€ìƒ‰í‚¤ì›Œë“œ", "ì¶œì²˜", "ê¸°ì‚¬ì¼ì", "ê¸°ì‚¬ì œëª©(ë§í¬)"]]

    with pd.ExcelWriter(output, engine="openpyxl") as writer:
        export_df.to_excel(writer, index=False, sheet_name="ë‰´ìŠ¤ìŠ¤í¬ë©")
        # ì»¬ëŸ¼ ë„ˆë¹„ ì¡°ì ˆ (ì„ íƒì‚¬í•­)
        worksheet = writer.sheets['ë‰´ìŠ¤ìŠ¤í¬ë©']
        worksheet.column_dimensions['D'].width = 80 
        
    return output.getvalue()

# =================================================
# 3. UI í™”ë©´ êµ¬ì„±
# =================================================
st.set_page_config(page_title="ì‹í’ˆ ë‰´ìŠ¤ ìŠ¤í¬ë©", layout="wide")
st.title("ğŸ“° ì‹í’ˆ/ìœ¡ê°€ê³µ ë‰´ìŠ¤ ìŠ¤í¬ë© ìë™í™”")

start_date, end_date = get_date_range()
st.info(f"ğŸ“… í˜„ì¬ ìˆ˜ì§‘ ì„¤ì • ê¸°ê°„: **{start_date} ~ {end_date}** (ì§€ë‚œì£¼ í† ìš”ì¼ ~ ì´ë²ˆì£¼ ëª©ìš”ì¼)")

# ì‚¬ì´ë“œë°” ì„¤ì •
with st.sidebar:
    st.header("ğŸ” ê²€ìƒ‰ ì„¤ì •")
    keyword = st.text_input("ê²€ìƒ‰ì–´ ì…ë ¥ (ì˜ˆ: ì†Œì‹œì§€ ë§ˆì¼€íŒ…)")
    min_score = st.slider("ì—°ê´€ë„ í•„í„° (í‚¤ì›Œë“œ í¬í•¨ ê°œìˆ˜)", 0, 5, 1)
    
    if st.button("ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹œì‘", use_container_width=True):
        if keyword:
            with st.spinner('êµ¬ê¸€ ë‰´ìŠ¤ë¥¼ ê¸ì–´ì˜¤ëŠ” ì¤‘...'):
                results = collect_news(keyword, start_date, end_date)
                st.session_state.news_results = [r for r in results if r['ì—°ê´€ë„ì ìˆ˜'] >= min_score]
                if not st.session_state.news_results:
                    st.warning("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        else:
            st.warning("í‚¤ì›Œë“œë¥¼ ì…ë ¥í•˜ì„¸ìš”.")

# ë©”ì¸í™”ë©´: ê²€ìƒ‰ ê²°ê³¼
col1, col2 = st.columns([1, 1])

with col1:
    st.subheader("ğŸ“Œ ê²€ìƒ‰ ê²°ê³¼")
    if st.session_state.news_results:
        selected_items = []
        for idx, item in enumerate(st.session_state.news_results):
            # ì²´í¬ë°•ìŠ¤ë¥¼ í†µí•´ ê¸°ì‚¬ ì„ íƒ
            is_selected = st.checkbox(
                f"{item['ê¸°ì‚¬ì¼ì']} | {item['ì¶œì²˜']} | {item['ì œëª©']}", 
                key=f"item_{idx}"
            )
            if is_selected:
                selected_items.append(item)
        
        # ì„ íƒëœ í•­ëª©ì„ ì„¸ì…˜ ì¹´íŠ¸ì— ì €ì¥
        st.session_state.cart = pd.DataFrame(selected_items)
    else:
        st.write("ì™¼ìª½ì—ì„œ ê²€ìƒ‰ì„ ì‹œì‘í•´ì£¼ì„¸ìš”.")

with col2:
    st.subheader("ğŸ›’ ì„ íƒëœ ê¸°ì‚¬ (ì—‘ì…€ ì €ì¥ ëª©ë¡)")
    if not st.session_state.cart.empty:
        # í™”ë©´ í‘œì‹œìš© (ìˆ˜ì‹ ì—†ëŠ” ë²„ì „)
        st.dataframe(
            st.session_state.cart[["ì¶œì²˜", "ê¸°ì‚¬ì¼ì", "ì œëª©"]], 
            use_container_width=True,
            hide_index=True
        )
        
        # ì—‘ì…€ ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
        excel_data = to_excel(st.session_state.cart)
        st.download_button(
            label="ğŸ“¥ ì„ íƒ ê¸°ì‚¬ ì—‘ì…€ ë‹¤ìš´ë¡œë“œ",
            data=excel_data,
            file_name=f"News_Scrap_{datetime.now().strftime('%Y%m%d')}.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            use_container_width=True
        )
        
        if st.button("ëª©ë¡ ì´ˆê¸°í™”"):
            st.session_state.cart = pd.DataFrame()
            st.rerun()
    else:
        st.info("ì„ íƒëœ ê¸°ì‚¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
