import streamlit as st
import pandas as pd
from gnews import GNews
from datetime import datetime, timedelta
from io import BytesIO
import json
import os

# =================================================
# 1. ì‹œìŠ¤í…œ ì´ˆê¸° ì„¤ì • ë° ë°ì´í„° ë¡œë“œ
# =================================================
DB_FILE = "keywords_db.json"

def load_keywords():
    if os.path.exists(DB_FILE):
        try:
            with open(DB_FILE, "r", encoding="utf-8") as f:
                return json.load(f)
        except:
            pass
    return {
        "ìœ í†µ": ["í™ˆí”ŒëŸ¬ìŠ¤", "ì´ë§ˆíŠ¸", "ë¡¯ë°ë§ˆíŠ¸"],
        "í¸ì˜ì ": ["GS25", "CU"],
        "ìœ¡ê°€ê³µ": ["ìœ¡ê°€ê³µ", "í–„", "ì†Œì‹œì§€", "ë¹„ì—”ë‚˜"],
        "HMR": ["HMR", "ë°€í‚¤íŠ¸"],
        "ëŒ€ì²´ìœ¡": ["ëŒ€ì²´ìœ¡", "ì‹ë¬¼ì„±"],
        "ì‹œì¥ë™í–¥": ["ê°€ê²©ì¸ìƒ", "ì›ê°€", "ë¬¼ê°€", "ì‹í’ˆ ë§¤ì¶œ"]
    }

def save_keywords(mapping):
    with open(DB_FILE, "w", encoding="utf-8") as f:
        json.dump(mapping, f, ensure_ascii=False, indent=4)

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "keyword_mapping" not in st.session_state:
    st.session_state.keyword_mapping = load_keywords()
if "news_results" not in st.session_state:
    st.session_state.news_results = []
if "cart_list" not in st.session_state:
    st.session_state.cart_list = []
if "reset_key" not in st.session_state:
    st.session_state.reset_key = 0

# =================================================
# 2. í•µì‹¬ ë¡œì§ (ê²€ìƒ‰ ë° ì—‘ì…€ ìƒì„±)
# =================================================
def get_fixed_date_range():
    today = datetime.today()
    days_since_friday = (today.weekday() - 4) % 7
    last_friday = today - timedelta(days=days_since_friday)
    return last_friday.date(), today.date()

def parse_news_date(date_str):
    try:
        return datetime.strptime(date_str, "%a, %d %b %Y %H:%M:%S %Z").date()
    except:
        return None

def get_relevance_score(title, desc, all_keywords):
    score = 0
    text = f"{title} {desc}".replace(" ", "").lower()
    title_only = title.replace(" ", "").lower()
    for kw in all_keywords:
        target = kw.replace(" ", "").lower()
        if target in title_only: score += 2
        elif target in text: score += 1
    return score

def collect_news_final(mapping, start_date, end_date):
    google_news = GNews(language="ko", country="KR", max_results=25)
    all_rows = []
    all_search_kws = [kw for sublist in mapping.values() for kw in sublist]
    exclude_keywords = ["ì¶œì‹œ", "ëŸ°ì¹­", "ì‹ ì œí’ˆ", "ì´ë²¤íŠ¸", "ì¦ì •", "í• ì¸í–‰ì‚¬", "í¬í† ì¡´", "íŒì—…ìŠ¤í† ì–´", "ì¦ì‹œ", "ì£¼ê°€", "ìƒí•œê°€"]
    
    progress_bar = st.progress(0)
    groups = list(mapping.items())
    
    for i, (group, sub_kws) in enumerate(groups):
        if not sub_kws: continue
        search_query = f"{group} ({' OR '.join(sub_kws)})"
        articles = google_news.get_news(search_query)
        
        for a in articles:
            title = a.get("title", "ì œëª© ì—†ìŒ")
            if any(ex in title for ex in exclude_keywords): continue
            
            article_date = parse_news_date(a.get("published date", ""))
            if not article_date or not (start_date <= article_date <= end_date): continue
            
            desc = a.get("description", "")
            score = get_relevance_score(title, desc, all_search_kws)
            
            all_rows.append({
                "í‚¤ì›Œë“œ": group,
                "ì¶œì²˜": a.get("publisher", {}).get("title", "ì¶œì²˜ ë¯¸ìƒ"),
                "ê¸°ì‚¬ì¼ì": article_date.strftime("%Y-%m-%d"),
                "ì œëª©": title,
                "ë§í¬": a.get("url", ""),
                "ì—°ê´€ë„ì ìˆ˜": score
            })
        progress_bar.progress((i + 1) / len(groups))
    
    unique_rows = {r['ë§í¬']: r for r in all_rows}.values()
    return sorted(list(unique_rows), key=lambda x: x['ì—°ê´€ë„ì ìˆ˜'], reverse=True)

def to_excel(data_list):
    df = pd.DataFrame(data_list)
    output = BytesIO()
    with pd.ExcelWriter(output, engine="xlsxwriter") as writer:
        if not df.empty:
            export_df = df[["í‚¤ì›Œë“œ", "ì¶œì²˜", "ê¸°ì‚¬ì¼ì", "ì œëª©"]]
            export_df.to_excel(writer, index=False, sheet_name="ë‰´ìŠ¤í´ë¦¬í•‘")
            
            workbook = writer.book
            worksheet = writer.sheets["ë‰´ìŠ¤í´ë¦¬í•‘"]
            link_format = workbook.add_format({'font_color': 'blue', 'underline': 1})
            
            for row_num, link in enumerate(df['ë§í¬']):
                worksheet.write_url(row_num + 1, 3, link, link_format, df.iloc[row_num]['ì œëª©'])
            
            worksheet.set_column('A:C', 15)
            worksheet.set_column('D:D', 80)
        else:
             pd.DataFrame().to_excel(writer, sheet_name="ë‰´ìŠ¤í´ë¦¬í•‘")
    return output.getvalue()

# =================================================
# 3. UI/UX êµ¬ì„± ë° ë°”êµ¬ë‹ˆ ë™ê¸°í™” ë¡œì§
# =================================================
st.set_page_config(page_title="ì§„ì£¼í–„ ë‰´ìŠ¤ í´ë¦¬í•‘", page_icon="ğŸ¥“", layout="wide")

# [í•µì‹¬ ìˆ˜ì •] keyë¥¼ ì‚¬ìš©í•˜ì—¬ ì²´í¬ë°•ìŠ¤ ìƒíƒœë¥¼ ì œì–´í•˜ëŠ” í•¨ìˆ˜
def toggle_cart_item(item, key):
    is_checked = st.session_state[key]
    current_links = [c['ë§í¬'] for c in st.session_state.cart_list]
    
    if is_checked:
        if item['ë§í¬'] not in current_links:
            st.session_state.cart_list.append(item)
    else:
        st.session_state.cart_list = [c for c in st.session_state.cart_list if c['ë§í¬'] != item['ë§í¬']]

# [ì¶”ê°€] í‚¤ì›Œë“œ ê´€ë¦¬ë¥¼ ìœ„í•œ Helper í•¨ìˆ˜
def dict_to_df(mapping):
    rows = []
    for category, keywords in mapping.items():
        for kw in keywords:
            rows.append({"ëŒ€ë¶„ë¥˜": category, "í‚¤ì›Œë“œ": kw})
    return pd.DataFrame(rows)

def df_to_dict(df):
    new_mapping = {}
    if not df.empty:
        for index, row in df.iterrows():
            cat = row["ëŒ€ë¶„ë¥˜"]
            kw = row["í‚¤ì›Œë“œ"]
            if pd.notna(cat) and pd.notna(kw) and str(cat).strip() and str(kw).strip():
                if cat not in new_mapping:
                    new_mapping[cat] = []
                new_mapping[cat].append(kw)
    return new_mapping

# ì‚¬ì´ë“œë°” ì„¤ì •
with st.sidebar:
    st.title("ğŸ¥“ ì§„ì£¼í–„ ë‰´ìŠ¤ë´‡")
    st.write("---")
    
    st.subheader("âš™ï¸ ê²€ìƒ‰ ì„¤ì •")
    start_d, end_d = get_fixed_date_range()
    
    st.info(f"ğŸ“… **ì–´ì°¨í”¼ ì´ë²ˆ ì£¼ ì–˜ê¸°ë§Œ í•©ë‹ˆë‹¤**\n\n{start_d.strftime('%m.%d')} (ê¸ˆ) ~ {end_d.strftime('%m.%d')} (ì˜¤ëŠ˜)")
    
    min_score = st.slider("ğŸ¯ **ì—°ê´€ë„ í•„í„°** (ë†’ì„ìˆ˜ë¡ ì •í™•)", 0, 5, 2)
    
    st.write("") 
    if st.button("ğŸ—‚ ì´ë²ˆ ì£¼ ì–´ì©” ìˆ˜ ì—†ëŠ” ë‰´ìŠ¤ ìˆ˜ì§‘", type="primary", use_container_width=True):
        with st.spinner('ğŸ•µï¸â€â™€ï¸ ë¶ˆê°€í”¼í•˜ê²Œ ë‰´ìŠ¤ë¥¼ ìˆ˜ì§‘ ì¤‘ì…ë‹ˆë‹¤'):
            st.session_state.news_results = collect_news_final(st.session_state.keyword_mapping, start_d, end_d)
            st.session_state.cart_list = [] 
            st.rerun()

    st.divider()
    
    st.subheader("ğŸ“ í‚¤ì›Œë“œ ê´€ë¦¬ì‹¤")
    st.caption("í‚¤ì›Œë“œë¥¼ ìˆ˜ì •í•˜ê±°ë‚˜ Delí‚¤ë¡œ ì‚­ì œí•˜ì„¸ìš”.")
    
    # [ìˆ˜ì •] ë°ì´í„° ì—ë””í„°ë¡œ í‚¤ì›Œë“œ ê´€ë¦¬ (ë“œë˜ê·¸ì•¤ë“œë¡­/ì‚­ì œ ê¸°ëŠ¥ êµ¬í˜„)
    current_df = dict_to_df(st.session_state.keyword_mapping)
    
    edited_df = st.data_editor(
        current_df,
        num_rows="dynamic",
        use_container_width=True,
        hide_index=True,
        column_config={
            "ëŒ€ë¶„ë¥˜": st.column_config.SelectboxColumn(
                "ëŒ€ë¶„ë¥˜",
                help="í‚¤ì›Œë“œì˜ ê·¸ë£¹ì„ ë³€ê²½í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
                width="small",
                options=list(st.session_state.keyword_mapping.keys()) + ["ì‹ ê·œê·¸ë£¹"],
                required=True
            ),
            "í‚¤ì›Œë“œ": st.column_config.TextColumn(
                "í‚¤ì›Œë“œ",
                width="medium",
                required=True
            )
        },
        key="keyword_editor"
    )
    
    # ë³€ê²½ì‚¬í•­ ì €ì¥ ë¡œì§
    if not current_df.equals(edited_df):
        new_mapping = df_to_dict(edited_df)
        st.session_state.keyword_mapping = new_mapping
        save_keywords(new_mapping)
        st.rerun()

# ë©”ì¸ ì˜ì—­
st.title("ğŸ“° Weekly News Clipping")
st.caption("íšŒì‚¬ ë•Œë¬¸ì— ì½ëŠ” ë‰´ìŠ¤, ëŒ€ì‹  ëª¨ì•„ë“œë¦½ë‹ˆë‹¤")
st.write("")

col_main, col_cart = st.columns([1.3, 0.7])

with col_main:
    st.subheader("ğŸ” ê²€ìƒ‰ ê²°ê³¼")
    
    all_categories = ["ì „ì²´"] + list(st.session_state.keyword_mapping.keys())
    tabs = st.tabs([f"  {cat}  " for cat in all_categories]) 
    
    cart_links = [item['ë§í¬'] for item in st.session_state.cart_list]
    
    for i, tab in enumerate(tabs):
        with tab:
            current_cat = all_categories[i]
            filtered_res = [r for r in st.session_state.news_results if r.get('ì—°ê´€ë„ì ìˆ˜', 0) >= min_score]
            if current_cat != "ì „ì²´":
                filtered_res = [r for r in filtered_res if r['í‚¤ì›Œë“œ'] == current_cat]
            
            # [ìˆ˜ì •] ìŠ¤í¬ë¡¤ ì˜ì—­ ê³ ì • (ë†’ì´ 600px)
            with st.container(height=600, border=False):
                if filtered_res:
                    st.success(f"ì´ {len(filtered_res)}ê±´ ë°œê²¬. ì‹¤ì œë¡œ ì“¸ ê±´ ëª‡ ê°œ ì•ˆ ë ê²ë‹ˆë‹¤ğŸ‰")
                    for idx, item in enumerate(filtered_res):
                        unique_key = f"cb_{current_cat}_{idx}_{item['ë§í¬']}"
                        
                        with st.container(border=True):
                            c_check, c_txt = st.columns([0.05, 0.95])
                            with c_check:
                                st.checkbox(
                                    "", 
                                    key=unique_key,
                                    value=(item['ë§í¬'] in cart_links), 
                                    on_change=toggle_cart_item,
                                    args=(item, unique_key)
                                )
                            with c_txt:
                                st.markdown(f"**[{item['í‚¤ì›Œë“œ']}] {item['ì œëª©']}**")
                                st.caption(f"ğŸ— {item['ì¶œì²˜']}  |  ğŸ—“ {item['ê¸°ì‚¬ì¼ì']}  |  â­ {item['ì—°ê´€ë„ì ìˆ˜']}ì ")
                                st.markdown(f"[ğŸ”— ê¸°ì‚¬ ì›ë¬¸ ë³´ëŸ¬ê°€ê¸°]({item['ë§í¬']})")
                else:
                    if st.session_state.news_results:
                        st.info(f"ğŸ’¦ '{current_cat}' ìª½ì€ ë”±íˆ ì“¸ë§Œí•œ ë‰´ìŠ¤ëŠ” ì—†ìŠµë‹ˆë‹¤")
                    else:
                        st.warning("ğŸ‘ˆ ì™¼ìª½ ì‚¬ì´ë“œë°”ì—ì„œ 'ë‰´ìŠ¤ ì°¾ê¸°' ë²„íŠ¼ì„ ëˆ„ë¥´ë©´ ìµœì†Œí•œ ë­”ê°€ëŠ” ë‚˜ì˜µë‹ˆë‹¤")

with col_cart:
    st.subheader("ğŸ›’ ì“¸ë§Œí•œ ë‰´ìŠ¤ ì¥ë°”êµ¬ë‹ˆ")
    
    # [ìˆ˜ì •] ì¥ë°”êµ¬ë‹ˆ ì˜ì—­ ìŠ¤í¬ë¡¤ ê³ ì •
    with st.container(height=600, border=True):
        if st.session_state.cart_list:
            st.markdown(f"**í˜„ì¬ {len(st.session_state.cart_list)}ê°œ ë³´ê´€ ì¤‘. ì¤„ì–´ë“¤ ì˜ˆì •**")
            
            cart_df = pd.DataFrame(st.session_state.cart_list)
            st.dataframe(
                cart_df[["í‚¤ì›Œë“œ", "ì œëª©"]], 
                use_container_width=True, 
                hide_index=True,
                height=300
            )
            
            st.write("")
            file_name = f"ì§„ì£¼í–„_ë‰´ìŠ¤í´ë¦¬í•‘_{end_d.strftime('%Y%m%d')}.xlsx"
            
            st.download_button(
                label="ğŸ“¥ ì¬ë¯¸ëŠ” ì—†ì§€ë§Œ í•„ìš”í•œ íŒŒì¼ ë‹¤ìš´ë¡œë“œ",
                data=to_excel(st.session_state.cart_list),
                file_name=file_name,
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                use_container_width=True,
                type="primary"
            )
            
            if st.button("ğŸ”„ í›„íšŒë¥¼ í¬í•¨í•˜ì—¬ ë‹¤ì‹œ ì²˜ìŒë¶€í„°", use_container_width=True):
                st.session_state.cart_list = []
                st.rerun()
        else:
            st.info("ì•„ì§ ì“¸ë§Œí•œ ê²Œ ì—†ìŠµë‹ˆë‹¤ ğŸ‚\n\nì™¼ìª½ ë¦¬ìŠ¤íŠ¸ì—ì„œ í•„ìš”í•œ ê¸°ì‚¬ë¥¼ ì²´í¬í•˜ë©´ ì—¬ê¸°ì— ë“¤ì–´ì™€ìš”.")
